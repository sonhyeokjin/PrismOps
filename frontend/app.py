import streamlit as st
import requests
import os
import time

# ----------------------------------------------------------------
# 1. ê¸°ë³¸ ì„¤ì • (ì‹¬í”Œí•˜ê²Œ)
# ----------------------------------------------------------------
st.set_page_config(
    page_title="PrismOps Chat",
    page_icon="ğŸ’",
    layout="centered"
)

st.title("ğŸ’ PrismOps Chat")
st.caption("Shadow Mode Enabled Architecture")

# [ì¤‘ìš”] ë°±ì—”ë“œ ì—°ê²° ì£¼ì†Œ ì„¤ì • (ì´ ë¶€ë¶„ì€ ìœ ì§€í•´ì•¼ ì—°ê²°ì´ ë©ë‹ˆë‹¤!)
BACKEND_URL = os.getenv("BACKEND_URL", "http://prism-gateway:8000")

# ----------------------------------------------------------------
# 2. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡)
# ----------------------------------------------------------------
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ì „ ëŒ€í™” ê¸°ë¡ í™”ë©´ì— ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ----------------------------------------------------------------
# 3. ì±„íŒ… ë¡œì§
# ----------------------------------------------------------------
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AI ì‘ë‹µ ì²˜ë¦¬
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        try:
            # ë°±ì—”ë“œ í˜¸ì¶œ
            payload = {
                "message": prompt,
                "model": "gpt-4o-mini"  # ê¸°ë³¸ ëª¨ë¸
            }

            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                response = requests.post(f"{BACKEND_URL}/chat", json=payload, timeout=10)

            if response.status_code == 200:
                result = response.json()
                answer = result.get("response", "")
                latency = result.get("latency", 0.0)

                # ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼ (í•œ ê¸€ìì”© ì¶œë ¥)
                for chunk in answer.split():
                    full_response += chunk + " "
                    time.sleep(0.05)
                    message_placeholder.markdown(full_response + "â–Œ")

                message_placeholder.markdown(full_response)

                # ì‹¬í”Œí•˜ê²Œ ë©”íƒ€ë°ì´í„° í‘œì‹œ
                st.info(f"âš¡ Latency: {latency:.2f}s | ğŸ¤– Model: {result.get('model')}")

            else:
                st.error(f"ì„œë²„ ì˜¤ë¥˜: {response.status_code}")
                st.write(response.text)

        except requests.exceptions.ConnectionError:
            st.error("ğŸš¨ ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
            st.caption(f"ì—°ê²° ì‹œë„ ì£¼ì†Œ: `{BACKEND_URL}`")
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    # ì‘ë‹µ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": full_response})